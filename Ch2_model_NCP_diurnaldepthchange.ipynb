{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb01f3f1-ee65-48f9-ad8f-9532c62b98b3",
   "metadata": {},
   "source": [
    "# Script for the Ch.2 of larval connectivity across the north central pacific with Diurnal Depth Change\n",
    "Authors: Taylor Ely and Johanna Wren  \n",
    "Script heavily based on code written by Gabi Mukai, Johanna Wren, and Don Kobayashi\n",
    "\n",
    "Started Working on this Date: November 19, 2025  \n",
    "\n",
    "This code is only for Caranx melampygus and Gymnomuraena zebra because these both have diurnal depth changes. Use other file for other species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce853627-b6ba-4fd2-96e2-9126bb3b0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import netCDF4\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from scipy import interpolate\n",
    "import math \n",
    "from pathlib import Path\n",
    "\n",
    "from parcels import FieldSet, ParticleSet, JITParticle, ScipyParticle, AdvectionRK4, DiffusionUniformKh, Variable, Field, GeographicPolar, Geographic\n",
    "from datetime import timedelta as timedelta\n",
    "import datetime\n",
    "from parcels.tools.converters import TimeConverter\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "from copy import copy\n",
    "from os.path import isfile\n",
    "import pytz\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4ed675-9c14-404b-b94f-7ebb9180a79b",
   "metadata": {},
   "source": [
    "### Create a fieldset\n",
    "We are creating a fieldset from HYCOM current files downloaded and stored on a drive. The fieldset is what OceanParcels uses to store all the information it needs for the flowfield that it moves particles through.\n",
    "\n",
    "The HYCOM data was downloaded using the `HYCOMdownload_ForTaylor.ipynb` script by Johanna Wren and grabs u and v currents for a region 100E-110W and 0-45N for depths 2m,6m,20m,60m,250m. The files are saved as HYCOM_yearmonthdayhour.nc. The HYCOM data can be found on the https://apdrc.soest.hawaii.edu/erddap/griddap/hawaii_soest_e9ba_92b1_0bcd. \n",
    "\n",
    "I should probably subset the depths I need for each species but not sure how to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8cc00d7-4af0-4243-b71b-66d332c1b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First NC time (seconds since 1970): 725846400.0\n"
     ]
    }
   ],
   "source": [
    "# Build fieldset\n",
    "fname = sorted(glob.glob(\"/Volumes/LAPS/redo_HYCOM/HYCOM_199[34]*\")) # get all the file names for 2 years\n",
    "\n",
    "# I need the first time of the first file because I fucked up the release times in my species files\n",
    "with Dataset(fname[0]) as nc:\n",
    "    nc_t0 = nc.variables['time'][0]\n",
    "\n",
    "print(\"First NC time (seconds since 1970):\", nc_t0)\n",
    "\n",
    "filenames = {'U': fname, 'V': fname, }\n",
    "variables = {'U': 'water_u', 'V': 'water_v'}\n",
    "dimensions = {}\n",
    "dimensions['U'] = {'lat': 'latitude', 'lon': 'longitude', 'depth': 'LEV', 'time': 'time'}\n",
    "dimensions['V'] = {'lat': 'latitude', 'lon': 'longitude', 'depth': 'LEV', 'time': 'time'}\n",
    "\n",
    "fieldset = FieldSet.from_netcdf(filenames, variables, dimensions, interp_method={'U': 'freeslip', 'V': 'freeslip', 'settle': 'nearest'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d72a42-344c-4387-9c64-eb1f06816db2",
   "metadata": {},
   "source": [
    "### Add diffusivity for randomness using 10 m^2/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ccff16d-4f20-4adf-942c-1d22e701cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the eddy diffusivity\n",
    "kh = 10.0   # This is the eddy diffusivity in m2/s\n",
    "fieldset.add_constant_field('Kh_zonal', kh, mesh='spherical')\n",
    "#zonal follows lat\n",
    "fieldset.add_constant_field('Kh_meridional', kh, mesh='spherical') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bfba15-0a55-4225-8e30-481148dadc37",
   "metadata": {},
   "source": [
    "### DELETE PARTICLES\n",
    "`DeleteParticles` allows for particles to be deleted when they exit the dispersal domain. This is applied to the borders of the domain but NOT to land. \n",
    "\n",
    "*NOTE: When currents are loaded into the fieldset the missing values over land get converted to zeros so particles that hit land just stop there and bunch up. This shouldn't be a problem for this application, but if it is, we can add land avoidance kernels.*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bea0cef4-e4c9-48ab-839f-9a5d4f1375d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Error\n",
    "def DeleteErrorParticle(particle, fieldset, time):\n",
    "    if particle.state == StatusCode.ErrorOutOfBounds:\n",
    "        particle.delete()\n",
    "\n",
    "# Delete Kernel\n",
    "def DeleteParticle(particle, fieldset, time):\n",
    "    print('deleted particle')\n",
    "    particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe6404-3cdf-4205-a33a-d8893b8845d3",
   "metadata": {},
   "source": [
    "### AGEING\n",
    "The `Ageing` kernel removes particles after a specific time period (PLD) by calling the `DeleteParticles` kernel. This allows you to run simulation for long periods of time while removing particles after a set number of days. We read in the PLD as a constant in the fieldset and this kernel grabs the PLD value from there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f4aa1d-1b99-4ca3-bb04-1d24e6133dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ageing(particle, fieldset, time):\n",
    "    particle.age += particle.dt\n",
    "    if particle.age >= fieldset.pld:\n",
    "        particle.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09375ff6-758b-405c-a1a2-f5f018fb61f1",
   "metadata": {},
   "source": [
    "### Add PLD\n",
    "Here we add the PLD as a constant to te fieldset. <span style=\"color:red\">**Don't forget to change the PLD for each species.**</span> For the model we only care about the max PLD and can select for the min-max in analysis after running model.  \n",
    "Caranx melampygus = 58 days (32-58)  \n",
    "Gymnomuraena zebra = 365 days (80-365)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e089c82-c0cc-40fb-8915-e3d0fb1d0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PLD to fieldset\n",
    "pld = 58  # in days\n",
    "fieldset.add_constant('pld', (pld*86400))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e60859a-b3db-4cf8-bcf5-78174678fa5b",
   "metadata": {},
   "source": [
    "### Define your particle type\n",
    "We are using a JIT particle but we are adding the age variable along with a release site variable. These variables will print to the output file, but it's easy to change to not show in the ouput file. \n",
    "\n",
    "The release site is just a number for the island the particle was released from and makes it much easier when we construct connectivity matrices in post processing. The island values are listed in a separate column in your LAPS_release_sites.csv file. \n",
    "\n",
    "Since we are calculating distance traveled we need to add a few more vaiables to our particle. We need the distance calculation from the `Distance` kernel above, as well as the previous lon and lat (that we added in the `AdvectionRK4` above). We are not writing the previous lon and lat in the output file so but we do want the distance written to the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13b5472e-2757-45a2-8fdb-ece2b276486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeingParticle(JITParticle):\n",
    "    age = Variable('age', dtype=np.float32, initial=0.0)\n",
    "    tday = Variable('tday', dtype=np.float32, initial=0.0)  # seconds since midnight\n",
    "    releaseSite = Variable('releaseSite', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd53711d-9409-4389-bed6-aee7455f4ade",
   "metadata": {},
   "source": [
    "### Define depth jumps by time of day (diurnal depth change)\n",
    "\n",
    "This is written by chatgpt so I have no faith that it will work but a starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaf2a068-5818-4b64-820d-18b378438f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiurnalDepthJump(particle, fieldset, time):\n",
    "\n",
    "    # Advance UTC-based clock\n",
    "    particle.tday += particle.dt\n",
    "    if particle.tday >= fieldset.seconds_per_day:\n",
    "        particle.tday -= fieldset.seconds_per_day\n",
    "\n",
    "    # Convert longitude to time offset (seconds)\n",
    "    # 360 degrees = 24 hours → 15 deg = 1 hour\n",
    "    lon_offset = (particle.lon / 360.0) * fieldset.seconds_per_day\n",
    "\n",
    "    # Local solar time in seconds\n",
    "    local_t = particle.tday + lon_offset\n",
    "\n",
    "    # Wrap safely (NO modulo)\n",
    "    if local_t >= fieldset.seconds_per_day:\n",
    "        local_t -= fieldset.seconds_per_day\n",
    "    else:\n",
    "        if local_t < 0.0:\n",
    "            local_t += fieldset.seconds_per_day\n",
    "\n",
    "    # Night: 18:00–06:00 local solar time\n",
    "    if local_t >= 64800.0:        # ≥ 18:00\n",
    "        particle.depth = fieldset.night_depth\n",
    "    else:\n",
    "        if local_t <= 21600.0:    # ≤ 06:00\n",
    "            particle.depth = fieldset.night_depth\n",
    "        else:\n",
    "            particle.depth = fieldset.day_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21897d4-7d29-4943-8427-36b18b12f7bd",
   "metadata": {},
   "source": [
    "### Set particle release locations\n",
    "Next, we instantiate a `ParticeSet` composed of `JITParticle`. \n",
    "\n",
    "`ParticleSet` holds release locations, the number of particles released, the release depth, and how often a particel should be released (daily, every 6h, etc.)  \n",
    "\n",
    "Particles are released from locations and times specified in a file. We use this if we want to release at for example all reef locations in the islands, or any other list of locations. If we are releaseing multiple particles for each site we need to repeat them with the dates and depths and that is what we are doing with the `np.repeat` part. \n",
    "\n",
    "You can add or omit `pdepth`, `time` and `repeatdt` for a one time release at the default `fieldset` depth (in a multi depth file default is top layer) and time. \n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red\">**Don't forget to change depth based on species.**</span> Here is the list for all species  \n",
    "Caranx melampygus 6m during the day and 20m at night  \n",
    "Gymnomuraena zebra 250m during the day and 60m at night   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88737d01-9ca2-461f-8910-aaa856490d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input file\n",
    "infile = pd.read_csv('caranx_releasefromsouth_1993.csv')\n",
    "\n",
    "# Set number of particles you want to release\n",
    "npart = infile.numberparticles\n",
    "\n",
    "# Set the release depth \n",
    "depth = 20\n",
    "\n",
    "# Convert longitudes from -180:180 to 0:360\n",
    "infile['lon'] = infile['lon'] % 360\n",
    "\n",
    "# Set day vs night release depth\n",
    "fieldset.add_constant(\"day_depth\", 6.0)\n",
    "fieldset.add_constant(\"night_depth\", 20.0)\n",
    "fieldset.add_constant(\"seconds_per_day\", 86400.0)\n",
    "\n",
    "# Fix release time. My release files are in seconds since 1970 in UTC but the fieldset is seconds from the first time of the nc files\n",
    "habitime2 = infile.release_time.values - nc_t0\n",
    "\n",
    "# Make vectors that repeat the release site and dept npart number of times\n",
    "habilon = np.repeat(infile.lon, npart)\n",
    "habilat = np.repeat(infile.lat, npart)\n",
    "habisite = np.repeat(infile.site_id, npart)\n",
    "habidepth = np.repeat(depth, len(habilon))\n",
    "habitime = np.repeat(habitime2, npart)\n",
    "\n",
    "# Define the pset\n",
    "pset = ParticleSet.from_list(fieldset=fieldset, \n",
    "                             pclass=AgeingParticle, \n",
    "                             lon=habilon,\n",
    "                             lat=habilat,\n",
    "                             depth=habidepth,\n",
    "                             releaseSite=habisite,\n",
    "                             time=habitime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6894d32c-7dd9-4504-9c7f-81cb61451ca5",
   "metadata": {},
   "source": [
    "### Advect particles\n",
    "\n",
    "To invoke the custom kernels we wrote earlier we need to combine them into a format Parcels can use. Simply string all the kernels together that you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74e170fc-6a37-4cdd-a7cf-a2a976bd4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine kernels you are using\n",
    "kernels = pset.Kernel(AdvectionRK4) + pset.Kernel(DiffusionUniformKh) + pset.Kernel(DiurnalDepthJump) + pset.Kernel(Ageing) + pset.Kernel(DeleteErrorParticle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064c244-7b93-4563-a4c6-1a210cf98377",
   "metadata": {},
   "source": [
    "Execute the advection. Depending on how many particles you release and the length of your release this may take some time.  \n",
    "\n",
    "Particles specified in ParticleSet are advected using kernels at a model_dt time step and printed in a netcdf file (outfile) at save_dt time steps. Particels reaching the limits of the domain are removed through recovery.  \n",
    "\n",
    "We are executing pset.execute here twice: the first time we are releaseing particles daily (or whatever interval we decided to use). To stop this, we then set pset.repeatdt = None followed by a new pset.execute that lasts for as long as the PLD. This way, each particle released will run to the end of the pld. That is, the releases will stop PLD days before the end of the run. So you shouldn't have any trajectories with NA's at the end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23c211-4ad5-462b-be4f-ebf951dc18ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Output files are stored in /Volumes/LAPS/output_model/Caranx/Ch2_caranx_1993_south_pld58_depth6to20_AprNov_night.zarr.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/parcels/lib/python3.13/site-packages/parcels/particleset.py:1127: ParticleSetWarning: Some of the particles have a start time difference that is not a multiple of outputdt. This could cause the first output of some of the particles that start later in the simulation to be at a different time than expected.\n",
      "  _warn_outputdt_release_desync(outputdt, starttime, self.particledata.data[\"time_nextloop\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4%|█                         | 1015200.0/26103600.0 [02:08<53:23, 7830.49it/s]"
     ]
    }
   ],
   "source": [
    "# Time step in model\n",
    "model_dt = timedelta(hours=1)\n",
    "\n",
    "# Time step to save to file\n",
    "save_dt = timedelta(days=1) # should this be 3hrs since the HYCOM files are every 3 hrs????\n",
    "\n",
    "# Length of model run\n",
    "first_release = habitime.min()\n",
    "last_release  = habitime.max()\n",
    "run_time = timedelta(seconds=(last_release - first_release) + pld * 86400)\n",
    "\n",
    "\n",
    "# Set output file name\n",
    "output_file = pset.ParticleFile(name=\"/Volumes/LAPS/output_model/Caranx/Ch2_caranx_1993_south_pld58_depth6to20_AprNov_night.zarr\", outputdt=save_dt)\n",
    "\n",
    "# don't print depth\n",
    "pset.set_variable_write_status('depth', False)\n",
    "\n",
    "# Execute and release daily during this timeframe\n",
    "# Execute and release daily during this timeframe\n",
    "pset.execute(kernels,\n",
    "            runtime=run_time,\n",
    "            dt=model_dt, \n",
    "            output_file=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7e0140-1e6b-4dd6-a71b-538c751820e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter, FFMpegWriter\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Load OceanParcels zarr\n",
    "# ----------------------------\n",
    "ds =  xr.open_zarr(\"/Volumes/LAPS/output_model/Caranx/Ch2_caranx_1993_south_pld58_depth6to20_AprNov_night.zarr\", consolidated=False)\n",
    "\n",
    "n_particles = 6000\n",
    "particle_subset = ds.isel(trajectory=slice(5000, n_particles))\n",
    "\n",
    "lons = particle_subset['lon'].values\n",
    "lats = particle_subset['lat'].values\n",
    "n_timesteps = lons.shape[1]\n",
    "\n",
    "# Wrap longitudes 0–360 → -180 to 180 for Cartopy\n",
    "lons_wrapped = ((lons + 180) % 360) - 180\n",
    "\n",
    "# Map setup\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "# Set central_longitude to 180 to center Pacific nicely\n",
    "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n",
    "\n",
    "# Add features\n",
    "ax.add_feature(cfeature.LAND.with_scale('50m'), facecolor='lightgray', zorder=0)\n",
    "ax.add_feature(cfeature.OCEAN.with_scale('50m'), facecolor='lightblue', zorder=0)\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale('50m'))\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linestyle=':')\n",
    "\n",
    "# Zoom to 100–250E and 0–45N\n",
    "lon_min, lon_max = 100, 250\n",
    "lat_min, lat_max = 0, 45\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "# Scatter\n",
    "scat = ax.scatter([], [], color='red', s=20, transform=ccrs.PlateCarree(), zorder=5)\n",
    "\n",
    "# Animation\n",
    "def update(frame):\n",
    "    scat.set_offsets(np.c_[lons_wrapped[:, frame], lats[:, frame]])\n",
    "    ax.set_title(f\"Particle trajectories - timestep {frame}\")\n",
    "    return scat,\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=n_timesteps, interval=200, blit=True)\n",
    "\n",
    "# Save GIF\n",
    "anim.save(\"caranx_1993_someparticles.gif\", writer=PillowWriter(fps=5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
